{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../dataset/email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "             ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "             ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "             ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "             ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "             ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "\n",
    "test_data_class = [0, 1, 0, 1, 0, 1] # 1 - negative, 0 - postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVocabList(data):\n",
    "    vocab_list = []\n",
    "    for example in data:\n",
    "        vocab_list.extend(example)\n",
    "    return list(set(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'garbage', 'problems', 'please', 'food', 'has', 'park', 'not', 'cute', 'ate', 'stupid', 'quit', 'love', 'to', 'licks', 'mr', 'my', 'buying', 'worthless', 'dalmation', 'flea', 'how', 'dog', 'stop', 'take', 'so', 'help', 'maybe', 'steak', 'him', 'posting', 'is']\n"
     ]
    }
   ],
   "source": [
    "vocab_list = buildVocabList(test_data)\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2Onehot(vocab_list, sentence):\n",
    "    res = np.zeros((len(vocab_list)))\n",
    "    for word in sentence:\n",
    "        res[vocab_list.index(word)] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  1. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      "  0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_vec = np.zeros((len(test_data), len(vocab_list)))\n",
    "for i in range(len(test_data)):\n",
    "    test_vec[i] = word2Onehot(vocab_list, test_data[i])\n",
    "print(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(c|\\mathbf{w})=\\frac{p(\\mathbf{w}|c)p(c)}{p(\\mathbf{w})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesTrainer(data_mat, data_class):\n",
    "    word_num = len(data_mat[0])\n",
    "    data_num = len(data_mat)\n",
    "    post_prob = np.sum(data_class)/float(6) #p(c_1) = p(1)\n",
    "    # nega_prob = 1 - post_prob # p(c_0) = p(0)\n",
    "    post_class_word = np.ones(word_num)\n",
    "    nega_class_word = np.ones(word_num)\n",
    "    post_num = 1.0\n",
    "    nega_num = 1.0\n",
    "    for i in range(data_num):\n",
    "        # print(i,\"-th data, class is \", test_data_class[i])\n",
    "        if data_class[i] == 0: # negative\n",
    "            nega_class_word += data_mat[i] # frequence of word in 0-class \n",
    "            # print(nega_class_word)\n",
    "            nega_num += sum(data_mat[i]) # num of word in 0-class\n",
    "            # print(nega_num)\n",
    "        else: # postive\n",
    "            post_class_word += data_mat[i]\n",
    "            # print(post_class_word)\n",
    "            post_num += sum(data_mat[i])\n",
    "            # print(post_num)\n",
    "    post_vec = np.log(post_class_word/post_num) # p(w|1)\n",
    "    nega_vec = np.log(nega_class_word/nega_num) # p(w|0)\n",
    "    return post_vec, nega_vec, post_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.99573227 -2.30258509 -2.99573227 -2.99573227 -2.30258509 -2.99573227\n",
      " -2.30258509 -2.30258509 -2.99573227 -2.99573227 -1.60943791 -2.30258509\n",
      " -2.99573227 -2.30258509 -2.99573227 -2.99573227 -2.99573227 -2.30258509\n",
      " -1.89711998 -2.99573227 -2.99573227 -2.99573227 -1.89711998 -2.30258509\n",
      " -2.30258509 -2.99573227 -2.99573227 -2.30258509 -2.99573227 -2.30258509\n",
      " -2.30258509 -2.99573227]\n",
      "[-2.52572864 -3.21887582 -2.52572864 -2.52572864 -3.21887582 -2.52572864\n",
      " -3.21887582 -3.21887582 -2.52572864 -2.52572864 -3.21887582 -3.21887582\n",
      " -2.52572864 -2.52572864 -2.52572864 -2.52572864 -1.83258146 -3.21887582\n",
      " -3.21887582 -2.52572864 -2.52572864 -2.52572864 -2.52572864 -2.52572864\n",
      " -3.21887582 -2.52572864 -2.52572864 -3.21887582 -2.52572864 -2.12026354\n",
      " -3.21887582 -2.52572864]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "post_vec, nega_vec, post_prob = naiveBayesTrainer(test_vec, test_data_class)\n",
    "print(post_vec)\n",
    "print(nega_vec)\n",
    "print(post_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[-0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -2.99573227 -0.         -0.         -0.         -2.99573227 -0.\n",
      " -0.         -2.99573227 -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.        ]\n",
      "-9.680344001221918\n",
      "-7.577185932924767\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample = ['love', 'my', 'dalmation']\n",
    "vec = word2Onehot(vocab_list, sample)\n",
    "print(vec)\n",
    "print(vec*post_vec)\n",
    "p1 = np.sum(vec * post_vec) + np.log(post_prob)\n",
    "p0 = np.sum(vec * nega_vec) + np.log(1-post_prob)\n",
    "print(p1)\n",
    "print(p0)\n",
    "if p1 >= p0:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesClassifier(input_vec, post_vec, nega_vec, post_prob):\n",
    "    p1 = np.sum(input_vec * post_vec) + np.log(post_prob)\n",
    "    p0 = np.sum(input_vec * nega_vec) + np.log(1-post_prob)\n",
    "    if p1 > p0: return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(naiveBayesClassifier(vec, post_vec, nega_vec, post_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
